{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "perceived-glucose",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tqdm import tqdm\n",
    "\n",
    "from tensorflow_asr.configs.config import Config\n",
    "from tensorflow_asr.datasets.asr_dataset import ASRSliceDataset\n",
    "from tensorflow_asr.featurizers.speech_featurizers import TFSpeechFeaturizer\n",
    "from tensorflow_asr.featurizers.text_featurizers import CharFeaturizer\n",
    "from tensorflow_asr.models.transducer.contextnet import ContextNet\n",
    "from tensorflow_asr.optimizers.schedules import TransformerSchedule\n",
    "from tensorflow_asr.utils import app_util\n",
    "from tensorflow_asr.utils import env_util\n",
    "from tensorflow_asr.gradient_visualisation.plotting_utils import make_directories\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "living-reception",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_weights(net):\n",
    "    return net.layers[0].get_weights()\n",
    "\n",
    "\n",
    "def obtain_direction(copy_of_the_weights):\n",
    "    direction1 = []\n",
    "    for w in copy_of_the_weights:\n",
    "        if len(w.shape) == 3:  # check for 3D tensor  or 1d-conv cnn layer  ---- this might be 2D tensor in case of low rank/depthwise seprable tensor\n",
    "            random_vector = tf.random.normal(w.shape, 0, 1, tf.float32)\n",
    "            w_norm_tf = tf.norm(tf.reshape(w, (w.shape[0], -1)), axis=1, keepdims=True)[:, :, None]\n",
    "            d_norm1_tf = tf.norm(tf.reshape(random_vector, (random_vector.shape[0], -1)), axis=1, keepdims=True)[:, :, None]\n",
    "            random_vector = random_vector * (w_norm_tf / (d_norm1_tf + 1e-10))\n",
    "            direction1.append(random_vector)\n",
    "        elif len(w.shape) == 4:\n",
    "            random_vector = tf.random.normal(w.shape, 0, 1, tf.float32)\n",
    "            w_norm_tf = tf.norm(tf.reshape(w, (w.shape[0], -1)), axis=1, keepdims=True)[:, :, None, None]\n",
    "            d_norm1_tf = tf.norm(tf.reshape(random_vector, (random_vector.shape[0], -1)), axis=1, keepdims=True)[:, :, None, None]\n",
    "            random_vector = random_vector * (w_norm_tf / (d_norm1_tf + 1e-10))\n",
    "            direction1.append(random_vector)\n",
    "        else:\n",
    "            direction1.append(tf.zeros_like(w))\n",
    "    return direction1\n",
    "\n",
    "\n",
    "tf.keras.backend.clear_session()\n",
    "env_util.setup_environment()\n",
    "\n",
    "DEFAULT_YAML = \"/Users/vaibhavsingh/Desktop/FILRCN/contextnet/config.yml\"\n",
    "\n",
    "tf.config.optimizer.set_experimental_options({\"auto_mixed_precision\": False})\n",
    "strategy = env_util.setup_strategy([0])\n",
    "\n",
    "config = Config(DEFAULT_YAML)\n",
    "speech_featurizer = TFSpeechFeaturizer(config.speech_config)\n",
    "text_featurizer = CharFeaturizer(config.decoder_config)\n",
    "\n",
    "tf.random.set_seed(0)\n",
    "test_dataset = ASRSliceDataset(\n",
    "    speech_featurizer=speech_featurizer,\n",
    "    text_featurizer=text_featurizer,\n",
    "    **vars(config.learning_config.test_dataset_config)\n",
    ")\n",
    "batch_size = config.learning_config.running_config.batch_size\n",
    "\n",
    "test_data_loader = test_dataset.create(batch_size)\n",
    "\n",
    "number_of_points = 9\n",
    "small_range = -1.0\n",
    "large_range = 1.0\n",
    "\n",
    "xcoordinates = np.linspace(small_range, large_range, num=number_of_points)\n",
    "ycoordinates = np.linspace(small_range, large_range, num=number_of_points)\n",
    "\n",
    "xcoord_mesh, ycoord_mesh = np.meshgrid(xcoordinates, ycoordinates)\n",
    "inds = np.array(range(number_of_points ** 2))\n",
    "s1 = xcoord_mesh.ravel()[inds]\n",
    "s2 = ycoord_mesh.ravel()[inds]\n",
    "coordinate = np.c_[s1, s2]\n",
    "\n",
    "directory_to_save = make_directories(\"loss_lists\")\n",
    "model_directory = \"/content/FILRCN/contextnet/checkpoints\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rural-diagram",
   "metadata": {},
   "outputs": [],
   "source": [
    "for filename in tqdm(sorted(os.listdir(model_directory))):\n",
    "    if not filename.endswith(\".h5\"):\n",
    "        print(filename)\n",
    "        continue\n",
    "    loss_file = filename.split('.')[0]\n",
    "    model_name = os.path.join(model_directory, filename)\n",
    "    print(model_name)\n",
    "    contextnet = ContextNet(**config.model_config, vocabulary_size=text_featurizer.num_classes)\n",
    "    contextnet.make(speech_featurizer.shape)\n",
    "    # contextnet.summary(line_length=100)\n",
    "    contextnet.load_weights(model_name, by_name=True)\n",
    "    contextnet.add_featurizers(speech_featurizer, text_featurizer)\n",
    "\n",
    "    optimizer = tf.keras.optimizers.Adam(\n",
    "        TransformerSchedule(\n",
    "            d_model=contextnet.dmodel,\n",
    "            warmup_steps=config.learning_config.optimizer_config.pop(\"warmup_steps\", 10000),\n",
    "            max_lr=(0.05 / math.sqrt(contextnet.dmodel))\n",
    "        ),\n",
    "        **config.learning_config.optimizer_config\n",
    "    )\n",
    "\n",
    "    contextnet.compile(\n",
    "        optimizer=optimizer,\n",
    "        steps_per_execution=1,\n",
    "        global_batch_size=1,\n",
    "        blank=text_featurizer.blank\n",
    "    )\n",
    "\n",
    "    converged_weights = get_weights(contextnet)\n",
    "\n",
    "    direction1 = obtain_direction(converged_weights)\n",
    "    direction2 = obtain_direction(converged_weights)\n",
    "\n",
    "    current_direction1 = direction1\n",
    "    current_direction2 = direction2\n",
    "    current_loader = test_data_loader\n",
    "\n",
    "    loss_list = np.zeros((number_of_points, number_of_points))\n",
    "    acc_list_greedy_char = np.zeros((number_of_points, number_of_points))\n",
    "    acc_list_beam_char = np.zeros((number_of_points, number_of_points))\n",
    "    acc_list_greedy_wer = np.zeros((number_of_points, number_of_points))\n",
    "    acc_list_beam_wer = np.zeros((number_of_points, number_of_points))\n",
    "    col_value = 0\n",
    "\n",
    "    index_list = []\n",
    "    for count, ind in tqdm(enumerate(inds)):\n",
    "        index_list.append(count)\n",
    "        coord = coordinate[count]\n",
    "        changes = [d0 * coord[0] + d1 * coord[1] for (d0, d1) in zip(current_direction1, current_direction2)]\n",
    "        k = np.add(changes, converged_weights)\n",
    "        contextnet.layers[0].set_weights(k)\n",
    "\n",
    "        loss = contextnet.evaluate(current_loader, batch_size=batch_size, use_multiprocessing=True, workers=8)\n",
    "        results = contextnet.predict(current_loader, verbose=1, use_multiprocessing=True, workers=8)\n",
    "        filepath = os.path.join(os.getcwd(), \"test.tsv\")\n",
    "        with open(filepath, \"w\") as openfile:\n",
    "            openfile.write(\"PATH\\tDURATION\\tGROUNDTRUTH\\tGREEDY\\tBEAMSEARCH\\n\")\n",
    "            for i, pred in enumerate(results):\n",
    "                groundtruth, greedy, beamsearch = [x.decode('utf-8') for x in pred]\n",
    "                path, duration, _ = test_dataset.entries[i]\n",
    "                openfile.write(f\"{path}\\t{duration}\\t{groundtruth}\\t{greedy}\\t{beamsearch}\\n\")\n",
    "\n",
    "        res = app_util.evaluate_results(filepath)\n",
    "        accuracy_gcer = 1 - res['greedy_cer']\n",
    "        accuracy_gwer = 1 - res['greedy_wer']\n",
    "        accuracy_bwer = 1 - res['beamsearch_wer']\n",
    "        accuracy_bcer = 1 - res['beamsearch_cer']\n",
    "\n",
    "        loss_list[col_value][ind % number_of_points] = loss\n",
    "        acc_list_greedy_char[col_value][ind % number_of_points] = accuracy_gcer\n",
    "        acc_list_greedy_wer[col_value][ind % number_of_points] = accuracy_gwer\n",
    "        acc_list_beam_wer[col_value][ind % number_of_points] = accuracy_bwer\n",
    "        acc_list_beam_char[col_value][ind % number_of_points] = accuracy_bcer\n",
    "\n",
    "        ind_compare = ind + 1\n",
    "        if ind_compare % number_of_points == 0:  col_value = col_value + 1\n",
    "        # delete the test file which is temporary\n",
    "        os.remove(filepath)\n",
    "\n",
    "    data = {'loss_list': [loss_list],\n",
    "            'greedy_char': [acc_list_greedy_char],\n",
    "            'greedy_wer': [acc_list_greedy_wer],\n",
    "            'beam_wer': [acc_list_beam_wer],\n",
    "            'beam_char': [acc_list_beam_char]\n",
    "            }\n",
    "\n",
    "    file_path_to_save_data = os.path.join(directory_to_save, loss_file) + \".pkl\"\n",
    "    with open(file_path_to_save_data, 'wb') as f:\n",
    "        pickle.dump(data, f)\n",
    "\n",
    "    f.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "serial-combine",
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_points = 9\n",
    "small_range = -1.0\n",
    "large_range = 1.0\n",
    "\n",
    "xcoordinates = np.linspace(small_range, large_range, num=number_of_points)\n",
    "ycoordinates = np.linspace(small_range, large_range, num=number_of_points)\n",
    "\n",
    "xcoord_mesh, ycoord_mesh = np.meshgrid(xcoordinates, ycoordinates)\n",
    "\n",
    "loss_lists_directory = os.path.join(os.getcwd(), \"loss_lists\")\n",
    "\n",
    "def create_viz(loss_list, acc_list, figure_directory, filename, title=\"none\"):\n",
    "    print(filename)\n",
    "    plt.figure(figsize=(5, 5))\n",
    "    if title != \"none\":\n",
    "        plt.title(\"Contour 2D\")\n",
    "    CS = plt.contour(xcoord_mesh, ycoord_mesh, loss_list, 20, zorder=1, cmap='terrain', linestyles='--')\n",
    "    plt.clabel(CS, inline=1, fontsize=8)\n",
    "    plt.xticks(fontsize=8, fontname=\"Courier New\")\n",
    "    plt.yticks(fontsize=8, fontname=\"Courier New\")\n",
    "    plt.savefig(figure_directory + \"/original_contour/\" + filename + \"OriginalContour.png\")\n",
    "\n",
    "    plt.figure(figsize=(5, 5))\n",
    "    if title != \"none\":\n",
    "        plt.title(\"Contour 2D \")\n",
    "    plt.contour(xcoord_mesh, ycoord_mesh, loss_list, 20, zorder=1, cmap='terrain', linestyles='--')\n",
    "    CS = plt.contourf(xcoord_mesh, ycoord_mesh, loss_list, 20, zorder=1, cmap='terrain', linestyles='--')\n",
    "    plt.clabel(CS, fontsize=8, inline=1, fmt='%2.1f')\n",
    "    plt.xticks(fontsize=8, fontname=\"Courier New\")\n",
    "    plt.yticks(fontsize=8, fontname=\"Courier New\")\n",
    "    plt.colorbar(CS)\n",
    "    plt.savefig(figure_directory + \"/original_contour_color/\" + filename + \"OriginalContourColor.png\")\n",
    "\n",
    "    plt.figure(figsize=(5, 5))\n",
    "    if title != \"none\":\n",
    "        plt.title(\"Contour 2D Log Scale\")\n",
    "    CS = plt.contour(xcoord_mesh, ycoord_mesh, np.log(loss_list), 20, zorder=1, cmap='terrain', linestyles='--')\n",
    "    plt.clabel(CS, inline=1, fontsize=8)\n",
    "    plt.xticks(fontsize=8, fontname=\"Courier New\")\n",
    "    plt.yticks(fontsize=8, fontname=\"Courier New\")\n",
    "    plt.savefig(figure_directory + \"/log_contour/\" + filename + \"LogScale.png\")\n",
    "\n",
    "    plt.figure(figsize=(5, 5))\n",
    "    if title != \"none\":\n",
    "        plt.title(\"Contour 2D Log Scale Color\")\n",
    "    plt.contour(xcoord_mesh, ycoord_mesh, np.log(loss_list), 20, zorder=1, cmap='terrain', linestyles='--')\n",
    "    CS = plt.contourf(xcoord_mesh, ycoord_mesh, np.log(loss_list), 20, zorder=1, cmap='terrain', linestyles='--')\n",
    "    plt.clabel(CS, fontsize=8, inline=1, fmt='%2.1f')\n",
    "    plt.xticks(fontsize=8, fontname=\"Courier New\")\n",
    "    plt.yticks(fontsize=8, fontname=\"Courier New\")\n",
    "    plt.savefig(figure_directory + \"/log_contour_color/\" + filename + \"LogScale.png\")\n",
    "\n",
    "    data = [\n",
    "        go.Surface(\n",
    "            x=xcoord_mesh, y=ycoord_mesh,\n",
    "            z=(loss_list.max() - loss_list.min()) * (acc_list - acc_list.min()) / (acc_list.max() - acc_list.min() + 1e-8) + loss_list.min(),\n",
    "            showscale=False, opacity=0.6, colorscale='Cividis',\n",
    "        ),\n",
    "        go.Surface(\n",
    "            x=xcoord_mesh, y=ycoord_mesh, z=loss_list, colorscale='Jet', cmin=0, cmax=30000, opacity=0.9,\n",
    "            contours=go.surface.Contours(z=go.surface.contours.Z(show=True, usecolormap=True, project=dict(z=True), ),\n",
    "                                         )\n",
    "        )\n",
    "    ]\n",
    "\n",
    "    layout = go.Layout(autosize=False,\n",
    "                       scene=dict(dict(\n",
    "                           xaxis=dict(range=[-1, 1],\n",
    "                                      backgroundcolor=\"rgb(163, 221, 240)\",\n",
    "                                      gridcolor=\"white\",\n",
    "                                      showbackground=True,\n",
    "                                      zerolinecolor=\"white\", tick0=-1.5, dtick=0.5, title_font_family=\"Courier New\"),\n",
    "                           yaxis=dict(range=[-1, 1],\n",
    "                                      backgroundcolor=\"rgb(91, 122, 133)\",\n",
    "                                      gridcolor=\"white\",\n",
    "                                      showbackground=True,\n",
    "                                      zerolinecolor=\"white\", tick0=-1.5, dtick=0.5, title_font_family=\"Courier New\"),\n",
    "                           zaxis=dict(range=[1, 30000],\n",
    "                                      backgroundcolor=\"rgb(204, 231, 240)\",\n",
    "                                      gridcolor=\"white\",\n",
    "                                      showbackground=True,\n",
    "                                      zerolinecolor=\"white\", title_font_family=\"Courier New\")),\n",
    "                           camera=dict(eye=dict(x=2, y=2, z=1.5))),\n",
    "                       margin=dict(l=50, r=10, b=20, t=10),\n",
    "                       width=500, height=500)\n",
    "    fig = go.Figure(data=data, layout=layout)\n",
    "    fig.update_layout(\n",
    "        font_family=\"Courier New\")\n",
    "    fig.update_xaxes(title_font_family=\"Courier New\")\n",
    "    fig.update_yaxes(title_font_family=\"Courier New\")\n",
    "\n",
    "    # iplot(fig)\n",
    "\n",
    "    fig.write_image(figure_directory + \"/loss_accuracy/\" + filename + \"Loss_Accuracy.png\", scale=1)\n",
    "\n",
    "    data = [\n",
    "        go.Surface(\n",
    "            x=xcoord_mesh, y=ycoord_mesh,\n",
    "            z=(np.log(loss_list).max() - np.log(loss_list).min()) * (acc_list - acc_list.min()) / (acc_list.max() - acc_list.min() + 1e-8) + np.log(\n",
    "                loss_list).min(),\n",
    "            showscale=False, opacity=0.6, colorscale='Cividis',\n",
    "        ),\n",
    "        go.Surface(\n",
    "            x=xcoord_mesh, y=ycoord_mesh, z=np.log(loss_list), colorscale='Jet', cmin=0, cmax=12, opacity=0.9,\n",
    "            contours=go.surface.Contours(z=go.surface.contours.Z(show=True, usecolormap=True, project=dict(z=True), ),\n",
    "                                         )\n",
    "        )\n",
    "    ]\n",
    "    layout = go.Layout(autosize=False,\n",
    "                       scene=dict(dict(\n",
    "                           xaxis=dict(range=[-1, 1],\n",
    "                                      backgroundcolor=\"rgb(163, 221, 240)\",\n",
    "                                      gridcolor=\"white\",\n",
    "                                      showbackground=True,\n",
    "                                      zerolinecolor=\"white\", tick0=-1.5, dtick=0.5, title_font_family=\"Courier New\"),\n",
    "                           yaxis=dict(range=[-1, 1],\n",
    "                                      backgroundcolor=\"rgb(91, 122, 133)\",\n",
    "                                      gridcolor=\"white\",\n",
    "                                      showbackground=True,\n",
    "                                      zerolinecolor=\"white\", tick0=-1.5, dtick=0.5, title_font_family=\"Courier New\"),\n",
    "                           zaxis=dict(range=[1, 12],\n",
    "                                      backgroundcolor=\"rgb(204, 231, 240)\",\n",
    "                                      gridcolor=\"white\",\n",
    "                                      showbackground=True,\n",
    "                                      zerolinecolor=\"white\", tick0=2, dtick=1, title_font_family=\"Courier New\")),\n",
    "                           camera=dict(eye=dict(x=2, y=2, z=1.5))),\n",
    "                       margin=dict(l=50, r=10, b=20, t=10),\n",
    "                       width=500, height=500)\n",
    "    fig = go.Figure(data=data, layout=layout)\n",
    "    fig.update_layout(\n",
    "        font_family=\"Courier New\")\n",
    "    fig.update_xaxes(title_font_family=\"Courier New\")\n",
    "    fig.update_yaxes(title_font_family=\"Courier New\")\n",
    "    # iplot(fig)\n",
    "    fig.write_image(figure_directory + \"/log_loss_accuracy/\" + filename + \"Log_Loss_Accuracy.png\", scale=1)\n",
    "\n",
    "\n",
    "def make_directories():\n",
    "    current_working_directory_abs = os.getcwd()\n",
    "    figs_directory_abs = os.path.join(current_working_directory_abs, \"figs\")\n",
    "    try:\n",
    "        os.mkdir(figs_directory_abs)\n",
    "        os.mkdir(os.path.join(figs_directory_abs, \"log_contour\"))\n",
    "        os.mkdir(os.path.join(figs_directory_abs, \"loss_accuracy\"))\n",
    "        os.mkdir(os.path.join(figs_directory_abs, \"log_contour_color\"))\n",
    "        os.mkdir(os.path.join(figs_directory_abs, \"log_loss_accuracy\"))\n",
    "        os.mkdir(os.path.join(figs_directory_abs, \"original_contour\"))\n",
    "        os.mkdir(os.path.join(figs_directory_abs, \"original_contour_color\"))\n",
    "        print(os.getcwd())\n",
    "    except Exception as e:\n",
    "        print(\"-------------Figures directory already exists-----------------\")\n",
    "        print(\"--------------The contents will be over-ridden-------------------\")\n",
    "        return figs_directory_abs\n",
    "    return figs_directory_abs\n",
    "\n",
    "\n",
    "figs_directory_abs = make_directories()\n",
    "\n",
    "\n",
    "def plot_loss_landscape(figs_directory_abs):\n",
    "    for file in tqdm(sorted(os.listdir(loss_lists_directory))):\n",
    "        filename = os.path.join(loss_lists_directory, file)\n",
    "        print(\"filenmes \", filename)\n",
    "        with open(filename, \"rb\") as f:\n",
    "            x_temp = pickle.load(f)\n",
    "        file = file.split('.')[0]\n",
    "        loss_list = x_temp['loss_list'][0]\n",
    "        acc_list_greedy_char = x_temp['greedy_char'][0]\n",
    "        acc_list_greedy_wer = x_temp['greedy_wer'][0]\n",
    "        acc_list_beam_wer = x_temp['beam_wer'][0]\n",
    "        acc_list_beam_char = x_temp['beam_char'][0]\n",
    "        acc_list = acc_list_beam_char\n",
    "\n",
    "        create_viz(loss_list, acc_list_beam_char, figs_directory_abs, file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "greatest-timber",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_loss_landscape(figs_directory_abs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "leading-blowing",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "\n",
    "import cv2\n",
    "\n",
    "def make_directory():\n",
    "    current_working_directory_abs = os.getcwd()\n",
    "    video_directory_abs = os.path.join(current_working_directory_abs, \"video\")\n",
    "    try:\n",
    "        os.mkdir(video_directory_abs)\n",
    "    except Exception as e:\n",
    "        print(\"--------------video directory already exists-----------------\")\n",
    "        print(\"--------------The contents will be over-ridden-------------------\")\n",
    "        return video_directory_abs\n",
    "\n",
    "    return video_directory_abs\n",
    "\n",
    "img_array = []\n",
    "size = (10,10)\n",
    "figures_working_dir = os.path.join(os.getcwd(), \"figs\")\n",
    "\n",
    "fname1 = figures_working_dir+'/log_loss_accuracy/*.png'\n",
    "fname2 = figures_working_dir+'/log_contour/*.png'\n",
    "\n",
    "video_directory = make_directory()\n",
    "\n",
    "\n",
    "for filename1, filename2 in zip(sorted(glob.glob(fname2)), sorted(glob.glob(fname1))):\n",
    "    print(filename1)\n",
    "    print(filename2)\n",
    "\n",
    "    image1 = cv2.imread(filename1)\n",
    "    image2 = cv2.imread(filename2)\n",
    "    height, width, layers = image1.shape\n",
    "    size = (width, height)\n",
    "    print(size)\n",
    "    height, width, layers = image2.shape\n",
    "    size = (width, height)\n",
    "    print(size)\n",
    "\n",
    "    vis = cv2.hconcat([image1, image2])\n",
    "    height, width, layers = vis.shape\n",
    "    size = (width, height)\n",
    "\n",
    "    img_array.append(vis)\n",
    "\n",
    "filename = video_directory + \"/contour_video.avi\"\n",
    "print(filename)\n",
    "out = cv2.VideoWriter(filename, cv2.VideoWriter_fourcc(*'DIVX'), 1, size)\n",
    "\n",
    "for i in range(len(img_array)):\n",
    "    out.write(img_array[i])\n",
    "\n",
    "out.release()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
